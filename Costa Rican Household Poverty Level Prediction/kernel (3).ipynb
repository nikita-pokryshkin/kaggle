{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d956dc0b6983484e17b7d3ed6ab267953a78a9d2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "pd.set_option('display.max_columns', 300)\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "mycols = [\"#66c2ff\", \"#5cd6d6\", \"#00cc99\", \"#85e085\", \"#ffd966\", \"#ffb366\", \"#ffb3b3\", \"#dab3ff\", \"#c2c2d6\"]\n",
    "sns.set_palette(palette = mycols, n_colors = 4)\n",
    "print('My colors are set!')\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "print('sklearn imported!')\n",
    "\n",
    "import lightgbm as lgb\n",
    "print('lightgbm imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('../input/train.csv')\n",
    "test_set = pd.read_csv('../input/test.csv')\n",
    "\n",
    "print(f'train set has {train_set.shape[0]} rows, and {train_set.shape[1]} features')\n",
    "print(f'test set has {test_set.shape[0]} rows, and {test_set.shape[1]} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "20b51144c6ff9d8da7a3f0eb4df12587cbbc553b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's take a look at target\n",
    "target = train_set['Target']\n",
    "target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6cac672fe0a74db69bed50e3f00cbaf0f0c2d6cd"
   },
   "source": [
    "## Outlier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e63c96ffa1a579326c997669f805f7437aa2b910",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#outlier in test set which rez_esc is 99.0\n",
    "test_set.loc[test_set['rez_esc'] == 99.0 , 'rez_esc'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "91474a271cb33326deae7dd9c9ab51986b0d3762"
   },
   "source": [
    "## Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cdf205203f38708c0c2895a5d3035b5b3d79557d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_na = train_set.isnull().sum().values / train_set.shape[0] *100\n",
    "df_na = pd.DataFrame(data_na, index=train_set.columns, columns=['Count'])\n",
    "df_na = df_na.sort_values(by=['Count'], ascending=False)\n",
    "\n",
    "missing_value_count = df_na[df_na['Count']>0].shape[0]\n",
    "\n",
    "print(f'We got {missing_value_count} rows which have missing value in train set ')\n",
    "df_na.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0faa5992610eb926fe8846828f4dde041e6ee0ae"
   },
   "source": [
    "*  **rez_esc** represents \"years behind in school\", missing value could be filled as 0\n",
    "*  **meaneduc** represents \"average years of education for adults (18+)\", missing value could be filled as 0\n",
    "*  **v18q1** really depends on v18q\n",
    "*  **v2a1** depends on tipovivi3\n",
    "\n",
    "We do not really need SQBxxxx features for polynomial in our case, and i will use fillna as 0 after at the last step of feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cade5d48350aa95149c4d719b06bed2ac42cb9bd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_na = test_set.isnull().sum().values / test_set.shape[0] *100\n",
    "df_na = pd.DataFrame(data_na, index=test_set.columns, columns=['Count'])\n",
    "df_na = df_na.sort_values(by=['Count'], ascending=False)\n",
    "\n",
    "missing_value_count = df_na[df_na['Count']>0].shape[0]\n",
    "\n",
    "print(f'We got {missing_value_count} rows which have missing value in test set ')\n",
    "df_na.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "954c123321909d1c399f04c92d07dba193d6985a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill na\n",
    "def repalce_v18q1(x):\n",
    "    if x['v18q'] == 0:\n",
    "        return x['v18q']\n",
    "    else:\n",
    "        return x['v18q1']\n",
    "\n",
    "train_set['v18q1'] = train_set.apply(lambda x : repalce_v18q1(x),axis=1)\n",
    "test_set['v18q1'] = test_set.apply(lambda x : repalce_v18q1(x),axis=1)\n",
    "\n",
    "train_set['v2a1'] = train_set['v2a1'].fillna(value=train_set['tipovivi3'])\n",
    "test_set['v2a1'] = test_set['v2a1'].fillna(value=test_set['tipovivi3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "07e0b4f570715a4549790e7448f883303efcb0fd"
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Replace object value, because some labels were generated whenever continuous variables have 1 or 0. The rule is to have being 1 yes=1 and no=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "baf15867d29fb88d76ae7a6d42dbe9ce81fcdcef",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['edjefe', 'edjefa']\n",
    "train_set[cols] = train_set[cols].replace({'no': 0, 'yes':1}).astype(float)\n",
    "test_set[cols] = test_set[cols].replace({'no': 0, 'yes':1}).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89e6aa2f9f8c5d04f65a0fc7adc40ec5aa0b13e9"
   },
   "source": [
    "It turns out orignial data lost one feature both for **roof** and **electricity**, so we manually add new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96c687f372df2a40687ec0bfecb2c0bcfe252f9f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set['roof_waste_material'] = np.nan\n",
    "test_set['roof_waste_material'] = np.nan\n",
    "train_set['electricity_other'] = np.nan\n",
    "test_set['electricity_other'] = np.nan\n",
    "\n",
    "def fill_roof_exception(x):\n",
    "    if (x['techozinc'] == 0) and (x['techoentrepiso'] == 0) and (x['techocane'] == 0) and (x['techootro'] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def fill_no_electricity(x):\n",
    "    if (x['public'] == 0) and (x['planpri'] == 0) and (x['noelec'] == 0) and (x['coopele'] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "train_set['roof_waste_material'] = train_set.apply(lambda x : fill_roof_exception(x),axis=1)\n",
    "test_set['roof_waste_material'] = test_set.apply(lambda x : fill_roof_exception(x),axis=1)\n",
    "train_set['electricity_other'] = train_set.apply(lambda x : fill_no_electricity(x),axis=1)\n",
    "test_set['electricity_other'] = test_set.apply(lambda x : fill_no_electricity(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e0d10ee77d5b15ca141498d9d94742ab2598425",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def owner_is_adult(x):\n",
    "    if x['age'] <= 18:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "train_set['head<18'] = train_set.apply(lambda x : owner_is_adult(x),axis=1)\n",
    "test_set['head<18'] = test_set.apply(lambda x : owner_is_adult(x),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "35c334bf4514fbe2c0ba6ce5c5fb64c922cff7df",
    "collapsed": true
   },
   "source": [
    "More feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "394ec0f30fcf45e7f35fbb871f6c05868ef12e17",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set['adult'] = train_set['hogar_adul'] - train_set['hogar_mayor']\n",
    "train_set['dependency_count'] = train_set['hogar_nin'] + train_set['hogar_mayor']\n",
    "train_set['dependency'] = train_set['dependency_count'] / train_set['adult']\n",
    "train_set['child_percent'] = train_set['hogar_nin']/train_set['hogar_total']\n",
    "train_set['elder_percent'] = train_set['hogar_mayor']/train_set['hogar_total']\n",
    "train_set['adult_percent'] = train_set['hogar_adul']/train_set['hogar_total']\n",
    "test_set['adult'] = test_set['hogar_adul'] - test_set['hogar_mayor']\n",
    "test_set['dependency_count'] = test_set['hogar_nin'] + test_set['hogar_mayor']\n",
    "test_set['dependency'] = test_set['dependency_count'] / test_set['adult']\n",
    "test_set['child_percent'] = test_set['hogar_nin']/test_set['hogar_total']\n",
    "test_set['elder_percent'] = test_set['hogar_mayor']/test_set['hogar_total']\n",
    "test_set['adult_percent'] = test_set['hogar_adul']/test_set['hogar_total']\n",
    "\n",
    "train_set['rent_per_adult'] = train_set['v2a1']/train_set['hogar_adul']\n",
    "train_set['rent_per_person'] = train_set['v2a1']/train_set['hhsize']\n",
    "test_set['rent_per_adult'] = test_set['v2a1']/test_set['hogar_adul']\n",
    "test_set['rent_per_person'] = test_set['v2a1']/test_set['hhsize']\n",
    "\n",
    "train_set['overcrowding_room_and_bedroom'] = (train_set['hacdor'] + train_set['hacapo'])/2\n",
    "test_set['overcrowding_room_and_bedroom'] = (test_set['hacdor'] + test_set['hacapo'])/2\n",
    "\n",
    "train_set['no_appliances'] = train_set['refrig'] + train_set['computer'] + train_set['television']\n",
    "test_set['no_appliances'] = test_set['refrig'] + test_set['computer'] + test_set['television']\n",
    "\n",
    "train_set['r4h1_percent_in_male'] = train_set['r4h1'] / train_set['r4h3']\n",
    "train_set['r4m1_percent_in_female'] = train_set['r4m1'] / train_set['r4m3']\n",
    "train_set['r4h1_percent_in_total'] = train_set['r4h1'] / train_set['hhsize']\n",
    "train_set['r4m1_percent_in_total'] = train_set['r4m1'] / train_set['hhsize']\n",
    "train_set['r4t1_percent_in_total'] = train_set['r4t1'] / train_set['hhsize']\n",
    "test_set['r4h1_percent_in_male'] = test_set['r4h1'] / test_set['r4h3']\n",
    "test_set['r4m1_percent_in_female'] = test_set['r4m1'] / test_set['r4m3']\n",
    "test_set['r4h1_percent_in_total'] = test_set['r4h1'] / test_set['hhsize']\n",
    "test_set['r4m1_percent_in_total'] = test_set['r4m1'] / test_set['hhsize']\n",
    "test_set['r4t1_percent_in_total'] = test_set['r4t1'] / test_set['hhsize']\n",
    "\n",
    "train_set['rent_per_room'] = train_set['v2a1']/train_set['rooms']\n",
    "train_set['bedroom_per_room'] = train_set['bedrooms']/train_set['rooms']\n",
    "train_set['elder_per_room'] = train_set['hogar_mayor']/train_set['rooms']\n",
    "train_set['adults_per_room'] = train_set['adult']/train_set['rooms']\n",
    "train_set['child_per_room'] = train_set['hogar_nin']/train_set['rooms']\n",
    "train_set['male_per_room'] = train_set['r4h3']/train_set['rooms']\n",
    "train_set['female_per_room'] = train_set['r4m3']/train_set['rooms']\n",
    "train_set['room_per_person_household'] = train_set['hhsize']/train_set['rooms']\n",
    "\n",
    "test_set['rent_per_room'] = test_set['v2a1']/test_set['rooms']\n",
    "test_set['bedroom_per_room'] = test_set['bedrooms']/test_set['rooms']\n",
    "test_set['elder_per_room'] = test_set['hogar_mayor']/test_set['rooms']\n",
    "test_set['adults_per_room'] = test_set['adult']/test_set['rooms']\n",
    "test_set['child_per_room'] = test_set['hogar_nin']/test_set['rooms']\n",
    "test_set['male_per_room'] = test_set['r4h3']/test_set['rooms']\n",
    "test_set['female_per_room'] = test_set['r4m3']/test_set['rooms']\n",
    "test_set['room_per_person_household'] = test_set['hhsize']/test_set['rooms']\n",
    "\n",
    "train_set['rent_per_bedroom'] = train_set['v2a1']/train_set['bedrooms']\n",
    "train_set['edler_per_bedroom'] = train_set['hogar_mayor']/train_set['bedrooms']\n",
    "train_set['adults_per_bedroom'] = train_set['adult']/train_set['bedrooms']\n",
    "train_set['child_per_bedroom'] = train_set['hogar_nin']/train_set['bedrooms']\n",
    "train_set['male_per_bedroom'] = train_set['r4h3']/train_set['bedrooms']\n",
    "train_set['female_per_bedroom'] = train_set['r4m3']/train_set['bedrooms']\n",
    "train_set['bedrooms_per_person_household'] = train_set['hhsize']/train_set['bedrooms']\n",
    "\n",
    "test_set['rent_per_bedroom'] = test_set['v2a1']/test_set['bedrooms']\n",
    "test_set['edler_per_bedroom'] = test_set['hogar_mayor']/test_set['bedrooms']\n",
    "test_set['adults_per_bedroom'] = test_set['adult']/test_set['bedrooms']\n",
    "test_set['child_per_bedroom'] = test_set['hogar_nin']/test_set['bedrooms']\n",
    "test_set['male_per_bedroom'] = test_set['r4h3']/test_set['bedrooms']\n",
    "test_set['female_per_bedroom'] = test_set['r4m3']/test_set['bedrooms']\n",
    "test_set['bedrooms_per_person_household'] = test_set['hhsize']/test_set['bedrooms']\n",
    "\n",
    "train_set['tablet_per_person_household'] = train_set['v18q1']/train_set['hhsize']\n",
    "train_set['phone_per_person_household'] = train_set['qmobilephone']/train_set['hhsize']\n",
    "test_set['tablet_per_person_household'] = test_set['v18q1']/test_set['hhsize']\n",
    "test_set['phone_per_person_household'] = test_set['qmobilephone']/test_set['hhsize']\n",
    "\n",
    "train_set['age_12_19'] = train_set['hogar_nin'] - train_set['r4t1']\n",
    "test_set['age_12_19'] = test_set['hogar_nin'] - test_set['r4t1']    \n",
    "\n",
    "train_set['escolari_age'] = train_set['escolari']/train_set['age']\n",
    "test_set['escolari_age'] = test_set['escolari']/test_set['age']\n",
    "\n",
    "train_set['rez_esc_escolari'] = train_set['rez_esc']/train_set['escolari']\n",
    "train_set['rez_esc_r4t1'] = train_set['rez_esc']/train_set['r4t1']\n",
    "train_set['rez_esc_r4t2'] = train_set['rez_esc']/train_set['r4t2']\n",
    "train_set['rez_esc_r4t3'] = train_set['rez_esc']/train_set['r4t3']\n",
    "train_set['rez_esc_age'] = train_set['rez_esc']/train_set['age']\n",
    "test_set['rez_esc_escolari'] = test_set['rez_esc']/test_set['escolari']\n",
    "test_set['rez_esc_r4t1'] = test_set['rez_esc']/test_set['r4t1']\n",
    "test_set['rez_esc_r4t2'] = test_set['rez_esc']/test_set['r4t2']\n",
    "test_set['rez_esc_r4t3'] = test_set['rez_esc']/test_set['r4t3']\n",
    "test_set['rez_esc_age'] = test_set['rez_esc']/test_set['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b32875cc4bb262c0abf8dbf3572a53b5de54a116",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set['dependency'] = train_set['dependency'].replace({np.inf: 0})\n",
    "test_set['dependency'] = test_set['dependency'].replace({np.inf: 0})\n",
    "\n",
    "print(f'train set has {train_set.shape[0]} rows, and {train_set.shape[1]} features')\n",
    "print(f'test set has {test_set.shape[0]} rows, and {test_set.shape[1]} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0de981d7bb9dab13b1986f51dd785126424de1c1",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "aggr_mean_list = ['rez_esc', 'dis', 'male', 'female', 'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', 'parentesco2',\n",
    "             'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12',\n",
    "             'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',]\n",
    "\n",
    "other_list = ['escolari', 'age', 'escolari_age']\n",
    "\n",
    "for item in aggr_mean_list:\n",
    "    group_train_mean = train_set[item].groupby(train_set['idhogar']).mean()\n",
    "    group_test_mean = test_set[item].groupby(test_set['idhogar']).mean()\n",
    "    new_col = item + '_aggr_mean'\n",
    "    df_train[new_col] = group_train_mean\n",
    "    df_test[new_col] = group_test_mean\n",
    "\n",
    "for item in other_list:\n",
    "    for function in ['mean','std','min','max','sum']:\n",
    "        group_train = train_set[item].groupby(train_set['idhogar']).agg(function)\n",
    "        group_test = test_set[item].groupby(test_set['idhogar']).agg(function)\n",
    "        new_col = item + '_' + function\n",
    "        df_train[new_col] = group_train\n",
    "        df_test[new_col] = group_test\n",
    "\n",
    "print(f'new aggregate train set has {df_train.shape[0]} rows, and {df_train.shape[1]} features')\n",
    "print(f'new aggregate test set has {df_test.shape[0]} rows, and {df_test.shape[1]} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "89a3bcb5a500b9a453df40f0d436cc1fb9b32513",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = df_test.reset_index()\n",
    "df_train = df_train.reset_index()\n",
    "\n",
    "train_agg = pd.merge(train_set, df_train, on='idhogar')\n",
    "test = pd.merge(test_set, df_test, on='idhogar')\n",
    "\n",
    "#fill all na as 0\n",
    "train_agg.fillna(value=0, inplace=True)\n",
    "test.fillna(value=0, inplace=True)\n",
    "print(f'new train set has {train_agg.shape[0]} rows, and {train_agg.shape[1]} features')\n",
    "print(f'new test set has {test.shape[0]} rows, and {test.shape[1]} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f59d61995955c7cf2a82f277c2c9cbee82511d6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#According to data descriptions,ONLY the heads of household are used in scoring. /\n",
    "#All household members are included in test + the sample submission, but only heads of households are scored.\n",
    "train = train_agg.query('parentesco1==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "84543b31c9523d0f262155d72cc727a54291a45a",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission = test[['Id']]\n",
    "\n",
    "#Remove useless feature to reduce dimension\n",
    "train.drop(columns=['idhogar','Id', 'tamhog', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n",
    "test.drop(columns=['idhogar','Id', 'tamhog', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n",
    "\n",
    "correlation = train.corr()\n",
    "correlation = correlation['Target'].sort_values(ascending=False)\n",
    "print(f'The most 20 positive feature: \\n{correlation.head(20)}')\n",
    "print('*'*50)\n",
    "\n",
    "print(f'The most 20 negative feature: \\n{correlation.tail(20)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c6c02498e833551038a47badf852146725bd320"
   },
   "source": [
    "## Model - LightGBM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f40f3a81291a3de6b9353d60ed1acc2f311819a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['Target']\n",
    "\n",
    "train.drop(columns=['Target'], inplace=True)\n",
    "\n",
    "#parameter value is copied from \n",
    "clf = lgb.LGBMClassifier(max_depth=-1, learning_rate=0.1, objective='multiclass',\n",
    "                             random_state=None, silent=True, metric='None', \n",
    "                             n_jobs=-1, n_estimators=10000, class_weight='balanced',\n",
    "                             colsample_bytree =  0.73, min_child_samples = 75, num_leaves = 14, subsample = 0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "11aecfe899b74c77d01b629455353cc2d6fe02fc",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kfold = 5\n",
    "kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n",
    "\n",
    "predicts_result = []\n",
    "for train_index, test_index in kf.split(train, y):\n",
    "    print(\"###\")\n",
    "    X_train, X_val = train.iloc[train_index], train.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "    clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "            early_stopping_rounds=400, verbose=100)\n",
    "    predicts_result.append(clf.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30f4c8922cfe9998a7b0c075483fe3d491899d07",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.argsort(clf.feature_importances_)[::-1]\n",
    "indices = indices[:75]\n",
    "\n",
    "# Visualise these with a barplot\n",
    "plt.subplots(figsize=(20, 15))\n",
    "g = sns.barplot(y=train.columns[indices], x = clf.feature_importances_[indices], orient='h', palette = mycols)\n",
    "g.set_xlabel(\"Relative importance\",fontsize=12)\n",
    "g.set_ylabel(\"Features\",fontsize=12)\n",
    "g.tick_params(labelsize=9)\n",
    "g.set_title(\"LightGBM feature importance\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2228d1164b8fc1faa238b30911310bb3d60519f5",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission['Target'] = np.array(predicts_result).mean(axis=0).round().astype(int)\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "49e22a3a9a24111aaef72f6e2a1fb42335f3d3b2",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68a7f3bc62671d44cc694ca8799b895221b60c53",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
